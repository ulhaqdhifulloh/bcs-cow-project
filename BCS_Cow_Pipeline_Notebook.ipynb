{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cf7d12",
   "metadata": {},
   "source": [
    "## STEP 1 — Inisialisasi path & bikin struktur minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8117195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\".\")\n",
    "DATA = BASE / \"data\"\n",
    "TRAIN = DATA / \"train\"\n",
    "VAL = DATA / \"val\"\n",
    "SEG = BASE / \"data_seg\"\n",
    "MODELS = BASE / \"models\"\n",
    "LOGS = BASE / \"logs\"\n",
    "\n",
    "for p in [TRAIN/\"rgb\", TRAIN/\"depth\", VAL/\"rgb\", VAL/\"depth\",\n",
    "          SEG/\"train/images\", SEG/\"train/labels\", SEG/\"val/images\", SEG/\"val/labels\",\n",
    "          MODELS, LOGS, BASE/\"web\", BASE/\"api\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Buat template labels.csv bila belum ada\n",
    "for split in [\"train\",\"val\"]:\n",
    "    csvp = DATA/split/\"labels.csv\"\n",
    "    if not csvp.exists():\n",
    "        csvp.write_text(\"cow_id,image_name_rgb,image_name_depth,bcs_label\\n\")\n",
    "\n",
    "print(\"OK: struktur siap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfacc2",
   "metadata": {},
   "source": [
    "## STEP 2 — (Opsional) Import & ekstraksi Dryad .bag → frame RGB + depth 16-bit\n",
    "Dryad rekamannya RealSense D435i (.bag ROS-style). Simpelnya, mohon ekstrak 1 frame tiap ~0.5–1.0 detik untuk mengurangi temporal leakage (sesuai saran README Dryad). Depth simpan uint16 lalu normalisasi di saat preprocessing agar tidak korup. https://datadryad.org/dataset/doi%3A10.5061/dryad.tqjq2bw4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan hanya jika kamu punya .bag dari Dryad di ./raw_bag/\n",
    "import os, cv2, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "HAS_RS = False\n",
    "try:\n",
    "    import pyrealsense2 as rs\n",
    "    HAS_RS = True\n",
    "except Exception as e:\n",
    "    print(\"pyrealsense2 tidak tersedia:\", e)\n",
    "\n",
    "RAW_BAG = BASE/\"raw_bag\"    # taruh .bag di sini\n",
    "OUT_SPLIT = \"train\"         # atau 'val'\n",
    "SAVE_EVERY_N_FRAMES = 15    # ~0.5s jika 30 FPS\n",
    "\n",
    "def extract_from_bag(bag_path: Path, out_split=\"train\", every_n=15):\n",
    "    assert HAS_RS, \"pyrealsense2 belum terpasang\"\n",
    "    rgb_dir = DATA/out_split/\"rgb\"\n",
    "    dpt_dir = DATA/out_split/\"depth\"\n",
    "    rgb_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_device_from_file(str(bag_path), repeat_playback=False)\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "    pipeline.start(config)\n",
    "    align = rs.align(rs.stream.color)\n",
    "\n",
    "    frame_idx = 0\n",
    "    saved = 0\n",
    "    try:\n",
    "        while True:\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            if not frames: break\n",
    "            frames = align.process(frames)\n",
    "            color = frames.get_color_frame()\n",
    "            depth = frames.get_depth_frame()\n",
    "            if not color or not depth: \n",
    "                continue\n",
    "\n",
    "            if frame_idx % every_n == 0:\n",
    "                c_img = np.asanyarray(color.get_data())\n",
    "                d_img = np.asanyarray(depth.get_data())  # uint16\n",
    "\n",
    "                base = f\"{bag_path.stem}_{frame_idx:06d}\"\n",
    "                cv2.imwrite(str(rgb_dir/f\"{base}.png\"), c_img)\n",
    "                cv2.imwrite(str(dpt_dir/f\"{base}.png\"), d_img)  # tetap uint16!\n",
    "                saved += 1\n",
    "            frame_idx += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "    finally:\n",
    "        try: pipeline.stop()\n",
    "        except: pass\n",
    "    return saved\n",
    "\n",
    "if RAW_BAG.exists():\n",
    "    total = 0\n",
    "    for f in RAW_BAG.glob(\"*.bag\"):\n",
    "        total += extract_from_bag(f, OUT_SPLIT, SAVE_EVERY_N_FRAMES)\n",
    "    print(f\"Saved frames: {total}\")\n",
    "else:\n",
    "    print(\"Lewati: folder raw_bag tidak ada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94d869",
   "metadata": {},
   "source": [
    "## STEP 3 — (Opsional) Import UNICT BCS DB ke struktur data/\n",
    "Setelah unduh, taruh citra ke data/train/rgb dan data/val/rgb. Isi labels.csv (bisa dari file meta/penilaian mingguan). Dataset ini 207 citra top-view + anotasi titik anatomi & label 2 assessor. https://iplab.dmi.unict.it/BCS/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d21b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh merge csv meta UNICT ke labels.csv (pseudo, sesuaikan kolom aslinya)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Misal kamu punya unict_meta.csv berisi: filename,bcs_label,cow_id\n",
    "unict_meta = Path(\"unict_meta.csv\")\n",
    "if unict_meta.exists():\n",
    "    meta = pd.read_csv(unict_meta)\n",
    "    # Bagi train/val sederhana: 80/20\n",
    "    mtrain = meta.sample(frac=0.8, random_state=42)\n",
    "    mval   = meta.drop(mtrain.index)\n",
    "\n",
    "    def write_labels(df, split):\n",
    "        rows = []\n",
    "        for _, r in df.iterrows():\n",
    "            rows.append({\n",
    "                \"cow_id\": r.get(\"cow_id\", \"UNK\"),\n",
    "                \"image_name_rgb\": r[\"filename\"],\n",
    "                \"image_name_depth\": \"\",           # kosong (UNICT 2D); isi jika ada depth pendamping\n",
    "                \"bcs_label\": r[\"bcs_label\"]\n",
    "            })\n",
    "        pd.DataFrame(rows).to_csv(DATA/split/\"labels.csv\", index=False)\n",
    "\n",
    "    write_labels(mtrain, \"train\")\n",
    "    write_labels(mval,   \"val\")\n",
    "    print(\"labels.csv dari UNICT ditulis.\")\n",
    "else:\n",
    "    print(\"Lewati: unict_meta.csv tidak ditemukan (isi manual labels.csv).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae604ef",
   "metadata": {},
   "source": [
    "## STEP 4 — Siapkan dataset segmentasi (YOLOv8-Seg)\n",
    "Ekspor dari Roboflow (format YOLOv8-Seg) atau pakai anotasi sendiri → letakkan ke data_seg/train/{images,labels} dan data_seg/val/{images,labels}. (Ada banyak dataset sapi instance-seg di Roboflow Universe). https://universe.roboflow.com/capstone-8gixe/cow-body-parts?utm_source=chatgpt.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, json\n",
    "from pathlib import Path\n",
    "\n",
    "seg_yaml = {\n",
    "    \"path\": str((SEG).resolve()),\n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"val/images\",\n",
    "    \"names\": [\"cow\"]\n",
    "}\n",
    "Path(\"yolo_seg_data.yaml\").write_text(yaml.dump(seg_yaml))\n",
    "print(Path(\"yolo_seg_data.yaml\").read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22895a",
   "metadata": {},
   "source": [
    "## STEP 5 — Train YOLOv8-Seg (fine-tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# pakai bobot dasar kecil agar edge-friendly\n",
    "seg_model = YOLO(\"yolov8s-seg.pt\")\n",
    "seg_model.train(\n",
    "    data=\"yolo_seg_data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    patience=10,\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# ambil best weights → simpan ke models/\n",
    "best = seg_model.ckpt_path if hasattr(seg_model, \"ckpt_path\") else \"runs/segment/train/weights/best.pt\"\n",
    "Path(MODELS/\"seg_yolov8s.pt\").write_bytes(Path(best).read_bytes())\n",
    "print(\"Saved:\", MODELS/\"seg_yolov8s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a420f",
   "metadata": {},
   "source": [
    "## STEP 6 — Infer mask untuk seluruh RGB (train/val) → simpan PNG mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "seg_model = YOLO(str(MODELS/\"seg_yolov8s.pt\"))\n",
    "\n",
    "def infer_and_save_masks(img_dir: Path, out_dir: Path, imgsz=640, conf=0.25):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for imgp in tqdm(sorted(img_dir.glob(\"*.png\")) + sorted(img_dir.glob(\"*.jpg\"))):\n",
    "        res = seg_model.predict(source=str(imgp), imgsz=imgsz, conf=conf, verbose=False)\n",
    "        if not res: \n",
    "            continue\n",
    "        r = res[0]\n",
    "        if r.masks is None:\n",
    "            # fallback: full mask (biar pipeline jalan)\n",
    "            im = cv2.imread(str(imgp))\n",
    "            mask = np.ones(im.shape[:2], np.uint8)*255\n",
    "        else:\n",
    "            # gabungkan semua instance 'cow' jadi satu mask\n",
    "            m = (r.masks.data.cpu().numpy() > 0.5).astype(np.uint8)  # [N,H,W]\n",
    "            mask = (m.max(axis=0)*255).astype(np.uint8)\n",
    "        cv2.imwrite(str(out_dir/f\"{imgp.stem}_mask.png\"), mask)\n",
    "\n",
    "for split in [\"train\",\"val\"]:\n",
    "    infer_and_save_masks(DATA/split/\"rgb\", DATA/split/\"masks\")\n",
    "print(\"Masks saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac3ebf",
   "metadata": {},
   "source": [
    "## STEP 7 — Ekstraksi fitur morfometrik dari depth 16-bit + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36365924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def load_depth_uint16(p: Path):\n",
    "    d = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)\n",
    "    if d is None:\n",
    "        raise FileNotFoundError(p)\n",
    "    assert d.dtype == np.uint16, f\"depth harus uint16, dapat {d.dtype}\"\n",
    "    return d\n",
    "\n",
    "def normalize01_uint16(d):\n",
    "    d = d.astype(np.float32)\n",
    "    return d / d.max() if d.max() > 0 else d\n",
    "\n",
    "def compute_features(depth_u16, mask_u8):\n",
    "    d = normalize01_uint16(depth_u16)\n",
    "    m = (mask_u8 > 0).astype(np.uint8)\n",
    "    if m.sum() == 0:\n",
    "        return dict(mean_depth=0., depth_variance=0., area_px=0, hw_ratio=0., body_volume_est=0.)\n",
    "    roi = d * (m>0)\n",
    "    h, w = m.shape\n",
    "    ys, xs = np.where(m>0)\n",
    "    hmin,hmax = ys.min(), ys.max()\n",
    "    wmin,wmax = xs.min(), xs.max()\n",
    "    box_h = hmax-hmin+1\n",
    "    box_w = wmax-wmin+1\n",
    "    return dict(\n",
    "        mean_depth=float(roi[roi>0].mean()),\n",
    "        depth_variance=float(roi[roi>0].var()),\n",
    "        area_px=int(m.sum()),\n",
    "        hw_ratio=float(box_h/box_w) if box_w>0 else 0.,\n",
    "        body_volume_est=float(roi.sum())/1e6  # skala proxy\n",
    "    )\n",
    "\n",
    "def build_feature_csv(split=\"train\"):\n",
    "    df = pd.read_csv(DATA/split/\"labels.csv\")\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rgb_name   = r[\"image_name_rgb\"]\n",
    "        depth_name = r[\"image_name_depth\"]\n",
    "        mask_path  = DATA/split/\"masks\"/f\"{Path(rgb_name).stem}_mask.png\"\n",
    "        if not mask_path.exists():\n",
    "            continue\n",
    "        if depth_name and (DATA/split/\"depth\"/depth_name).exists():\n",
    "            depth_u16 = load_depth_uint16(DATA/split/\"depth\"/depth_name)\n",
    "        else:\n",
    "            # Kalau tidak ada depth (misal UNICT), skip baris ini atau set fitur nol\n",
    "            # di sini aku skip untuk menjaga kualitas sinyal fitur\n",
    "            continue\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        feats = compute_features(depth_u16, mask)\n",
    "        feats.update({\n",
    "            \"cow_id\": r[\"cow_id\"],\n",
    "            \"image_name_rgb\": rgb_name,\n",
    "            \"image_name_depth\": depth_name,\n",
    "            \"bcs_label\": float(r[\"bcs_label\"])\n",
    "        })\n",
    "        rows.append(feats)\n",
    "    fe = pd.DataFrame(rows)\n",
    "    fe.to_csv(DATA/split/\"features.csv\", index=False)\n",
    "    return fe\n",
    "\n",
    "train_fe = build_feature_csv(\"train\")\n",
    "val_fe   = build_feature_csv(\"val\")\n",
    "train_fe.head(), val_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44b467",
   "metadata": {},
   "source": [
    "## STEP 8 — Training model BCS (Regresi dan opsi Ordinal)\n",
    "Praktik dari JDS 2024 menggunakan pendekatan ordinal untuk BCS 1–5 (step 0.25) ketika menganalisis agreement; di sini kuberi 2 opsi:\n",
    "\n",
    "(A) MLPRegressor (kontinu)\n",
    "\n",
    "(B) Ordinal logistic (mord) — kalau kamu ingin metrik klasifikasi yang sejalan dengan skala ordinal. \n",
    "\n",
    "https://pubmed.ncbi.nlm.nih.gov/37977440/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, cohen_kappa_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def as_Xy(fe):\n",
    "    X = fe[['mean_depth','depth_variance','area_px','hw_ratio','body_volume_est']].values\n",
    "    y = fe['bcs_label'].values\n",
    "    return X, y\n",
    "\n",
    "train_fe = pd.read_csv(DATA/\"train\"/\"features.csv\")\n",
    "X, y = as_Xy(train_fe)\n",
    "\n",
    "# -----------------------------\n",
    "# (A) Regressor kontinu (MLP)\n",
    "# -----------------------------\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "reg = MLPRegressor(hidden_layer_sizes=(128,64), activation='relu',\n",
    "                   random_state=42, max_iter=600)\n",
    "reg.fit(X_tr, y_tr)\n",
    "pred = reg.predict(X_te)\n",
    "print(\"Regressor  MAE=\", mean_absolute_error(y_te, pred), \" R2=\", r2_score(y_te, pred))\n",
    "\n",
    "# 5-fold CV (MAE)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_mae = -cross_val_score(reg, X, y, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
    "print(\"5-fold MAE:\", cv_mae.mean(), \"+/-\", cv_mae.std())\n",
    "\n",
    "# simpan\n",
    "joblib.dump(reg, MODELS/\"bcs_regressor.pkl\")\n",
    "print(\"Saved:\", MODELS/\"bcs_regressor.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# (B) Ordinal (opsional)\n",
    "# -----------------------------\n",
    "USE_ORDINAL = False\n",
    "try:\n",
    "    import mord\n",
    "    USE_ORDINAL = True\n",
    "except:\n",
    "    print(\"mord belum terpasang; lewati ordinal.\")\n",
    "\n",
    "if USE_ORDINAL:\n",
    "    # map nilai 1..5 (step 0.25) ke kelas ordinal 0..16\n",
    "    def to_ord_class(v): \n",
    "        idx = int(round((v - 1.0) / 0.25))\n",
    "        return max(0, min(16, idx))\n",
    "    y_ord = np.array([to_ord_class(v) for v in y])\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y_ord, test_size=0.2, random_state=42)\n",
    "    ord_model = mord.LogisticAT(alpha=1.0)\n",
    "    ord_model.fit(X_tr, y_tr)\n",
    "    y_pred_ord = ord_model.predict(X_te)\n",
    "\n",
    "    # metrik agreement (kelas dibawa ke 1..5 step 0.25)\n",
    "    def from_ord_class(k): return 1.0 + 0.25*int(k)\n",
    "    y_true_c = np.array([from_ord_class(k) for k in y_te])\n",
    "    y_pred_c = np.array([from_ord_class(k) for k in y_pred_ord])\n",
    "\n",
    "    def pct_agree(y_true, y_pred, tol):\n",
    "        return np.mean(np.abs(y_true - y_pred) <= tol)\n",
    "\n",
    "    print(\"Ordinal — exact:\", pct_agree(y_true_c, y_pred_c, 0.00))\n",
    "    print(\"Ordinal — ±0.25:\", pct_agree(y_true_c, y_pred_c, 0.25))\n",
    "    print(\"Ordinal — ±0.50:\", pct_agree(y_true_c, y_pred_c, 0.50))\n",
    "    # Kappa tertimbang (kuadratik)\n",
    "    # untuk kappa, konversi ke indeks kelas 0..16\n",
    "    print(\"Ordinal — κw:\", cohen_kappa_score(y_te, y_pred_ord, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39e375",
   "metadata": {},
   "source": [
    "## STEP 9 — Evaluasi pada set validasi (pakai data/val/features.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, cohen_kappa_score\n",
    "import joblib\n",
    "\n",
    "val_fe = pd.read_csv(DATA/\"val\"/\"features.csv\")\n",
    "Xv = val_fe[['mean_depth','depth_variance','area_px','hw_ratio','body_volume_est']].values\n",
    "yv = val_fe['bcs_label'].values\n",
    "\n",
    "reg = joblib.load(MODELS/\"bcs_regressor.pkl\")\n",
    "pv = reg.predict(Xv)\n",
    "\n",
    "def pct_agree(y_true, y_pred, tol):\n",
    "    return np.mean(np.abs(y_true - y_pred) <= tol)\n",
    "\n",
    "print(\"[VAL] MAE=\", mean_absolute_error(yv, pv), \" R2=\", r2_score(yv, pv))\n",
    "print(\"[VAL] exact:\", pct_agree(yv, pv, 0.00))\n",
    "print(\"[VAL] ±0.25:\", pct_agree(yv, pv, 0.25))\n",
    "print(\"[VAL] ±0.50:\", pct_agree(yv, pv, 0.50))\n",
    "\n",
    "# kelas bulat (1..5) untuk kappa (opsional)\n",
    "def to_class05(v): return int(round(v))  # bulat ke integer 1..5\n",
    "yvc = np.array([to_class05(v) for v in yv])\n",
    "pvc = np.array([to_class05(v) for v in pv])\n",
    "print(\"[VAL] κw (kuadratik) =\", cohen_kappa_score(yvc, pvc, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1a34c",
   "metadata": {},
   "source": [
    "## STEP 10 — Inferensi satu gambar RGB-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, joblib\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "reg = joblib.load(MODELS/\"bcs_regressor.pkl\")\n",
    "seg_model = YOLO(str(MODELS/\"seg_yolov8s.pt\"))\n",
    "\n",
    "def predict_single(rgb_path: Path, depth_path: Path):\n",
    "    # mask\n",
    "    r = seg_model.predict(source=str(rgb_path), imgsz=640, conf=0.25, verbose=False)[0]\n",
    "    if r.masks is None:\n",
    "        # fallback: full mask\n",
    "        mask = np.ones(cv2.imread(str(rgb_path)).shape[:2], np.uint8)*255\n",
    "    else:\n",
    "        m = (r.masks.data.cpu().numpy() > 0.5).astype(np.uint8)\n",
    "        mask = (m.max(axis=0)*255).astype(np.uint8)\n",
    "\n",
    "    # depth\n",
    "    d = cv2.imread(str(depth_path), cv2.IMREAD_UNCHANGED)\n",
    "    d = d.astype(np.float32)\n",
    "    d = d / d.max() if d.max() > 0 else d\n",
    "\n",
    "    # fitur (samakan dengan STEP 7)\n",
    "    roi = d * (mask>0)\n",
    "    h, w = mask.shape\n",
    "    ys, xs = np.where(mask>0)\n",
    "    if len(ys)==0:\n",
    "        return dict(bcs_pred=None, note=\"mask kosong\")\n",
    "    box_h, box_w = ys.max()-ys.min()+1, xs.max()-xs.min()+1\n",
    "    X = np.array([[\n",
    "        roi[roi>0].mean(),\n",
    "        roi[roi>0].var(),\n",
    "        (mask>0).sum(),\n",
    "        box_h/box_w if box_w>0 else 0.,\n",
    "        roi.sum()/1e6\n",
    "    ]], dtype=np.float32)\n",
    "    pred = float(reg.predict(X)[0])\n",
    "    return dict(bcs_pred=pred)\n",
    "\n",
    "# contoh:\n",
    "# predict_single(Path(\"data/val/rgb/example.png\"), Path(\"data/val/depth/example.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
